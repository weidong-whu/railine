\section{Methodology}

The flow of our methodology is presented in Figure 1.
We take aerial images of the railway area as input,
for which SfM and point clouds are used in advanced with existing software.
We first extract the image line and convert it to a space line with the locally optimal plane of the point cloud.
Then,
we cluster the single 3D line to RT candidates with the frame work derived from DBSCAN,  
during which the texture information of multiple images extracted from ResNet is used as one of the inlier distance.
Having obtained the RT cluster, 
we then trace and reconstruct the vector-based RT in the Kalman framwork,
which fully exploits the RT structure and the multi-view geometries to resolve the uncertainty caused by initial image line segment extraction and the point cloud error.
The railway-track pair is the start seed of our Kalman method.
We first convert image lines to 3D lines with the local optimal plane of the point cloud.
Then,
we cluster the single 3D line to RT pairs with DBSCAN frame work,  
during which the deep feature of multiple images is used as the inlier distance.





\subsection{Railway track with Kalman filter}

Let us first introduce the Kalman filter that optimize the \textit{RLP} without the geometry constraint between each other.
The state to be estimated is the two points and directions on the the \textit{RLP}:
\begin{equation}
\mathbf{x} = \begin{bmatrix}
    \mathbf p_1,\mathbf d_1,\mathbf p_2,\mathbf d_2 
\end{bmatrix}^ \top,
\end{equation}
where $\mathbf p_i=\left(x_i, y_i, z_i\right)$ denotes the position 
and $\mathbf d_i=\left(dx_i, dy_i, dz_i\right)$ is the normalized vector represents the direction.
Then,
the linear stochastic difference equation govern the state transition is
\begin{equation}
        \mathbf{x}_{k+1}= 
        \operatorname{diag} \left(\mathrm I,t \! \cdot \! \mathrm I, \mathrm I, t \! \cdot \! \mathrm I \right) \mathbf{x}_{k} + \mathbf{w}_k,
        \label {eq_statetransition}
\end{equation}
where $\mathrm I_{3\times3}$ is the identity matrix and $p \left(\mathbf w_k \right) \sim N(0, Q)$.
In each transition,
we can reconstruct the 3D line with multiple images (\cref*{sec_linereconstruction} ),
with which the observed position and direction related to $\mathbf x_k$ can be obtained.
Thus,
the measurement can be the same as $\mathbf x_k$,
and the general Kalman filter to track the \textit{RPL} is
\begin{equation}
    \mathbf {\hat x}_k =\mathbf {\hat x}_k^{\mbox -}+ \mathrm K\left(\mathbf z_k - \mathbf {\hat x}_k^{\mbox -}\right),\quad
    \mathbf z_k = \mathbf x_k+ \mathbf v_k,
\end{equation}
where $p \left(\mathbf v_k \right) \sim N(0, R)$,
$\mathbf {\hat x}_k^{\mbox -}$ is the prediction with \cref{eq_statetransition},
and $\mathrm K$ is the Kalman gain that iteratively calculated from the estimate error.
Please refer to (ref) for the details of Kalman gain. 

Now we add two geometry constraints of the \textit{RLP} to the filter process:
(1) $\mathbf d_1$ and $\mathbf d_2$ should be as close as possible;
and (2) The change in distance between $\mathbf p_1$ and $\mathbf p_2$ is as small as possible.


\subsection{Accurate railway line reconstruction}
\label{sec_linereconstruction}

\subsection{The seed generation for railway track}
We construct the rough 3D line based on the dense point cloud.
Given the end point $\mathbf p$ of a 2D line segment,
we randomly sample three space points around $\mathbf p$ to construct the plane $\pi$,
and we cast a ray $\mathbf r$ passing through $\mathbf p$ from the camera center.
Then,
the 3D point candidate $\mathrm P \in R ^ {3\times1}$ for $\mathbf p$ can be obtained by $\mathbf r$-to-$\pi$ intersection,
and the candidate 3D line $\mathrm L$ can be represented by the two 3D point:
\begin{equation}
    L =\left\{\textit{inter} \left(\pi,\mathbf r_1\right),\textit{inter} \left(\pi,\mathbf r_2\right)  \right\},
\end{equation}
where $\mathbf r_1$ and $\mathbf r_2$ are the rays of the two endpoints,
and \textit{inter} calculates the ray-to-plane intersection.
After random sampling of $n$ times,
we obtain a set of candidate 3D lines $\left\{ L\right\}_{i=1}^n$ and use the LMEDS algorithm,
which does not require an inlier threshold, to confirm the best 3D line for a 2D line:
\begin{equation}
    L^* = \arg\min_{L_i} \text{median} \left\{ d_{ij}\right\}_{j=1}^n ,
\end{equation}
where $d_{ij}$ is the projection distance between $L_i$ and $L_j$.  

We group two 3D lines as a RT pair based on their angle $\theta_{i,j}$,
overlap $o_{i,j}$,
and projection distance $d_{i,j}$:
\begin{equation}
   \left\{ RT= \left(L_i, L_j\right) \mid \theta_{i,j} < t_\theta, o_{i,j} > t_o, d_{i,j} \in I  \right\},
    \label{eq_geometrycons}
\end{equation}
$\theta_{i,j}$ and $o_{i,j}$are easy to choose,
e.g.,
$5^\circ$ and 60\%,
because the RT pair is parallel and highly overlapped;
while the interval $I$ needs the rough width $\omega$ between the two RT,
which can be acquired from construction standards or point clouds.
We recommend setting $I=\left[2/3\omega,4/3\omega\right]$ that uses one-third of $\omega$ as the margin of error.
Because a 3D line may satisfy \cref{eq_geometrycons} with many others,
the greedy algorithm is used to assign the candidate pair,
which uses the sum of the overlap rate as the maximum score.

We sort the RT based on their scores of the geometry alignment and select the top 10\% RT and use contextual information to further validate the RT pair.
In detail,
if the RT's central line is within $1^\circ$ and $t$ projection distance with another RT,
its score is increased by $\mathcal{N}\left(\mu, \left(t/3\right)^2\right)$.
we use the global average pooling layer in ResNet50 to describe the feature of the RT pair.
Because it has been trained on massive amounts of data and can capture texture information for classification in the absence of labels.
Also, 
we re-transform the image blocks to reduce the ambiguity caused by scale and rotation.
After extraction of RT features, 
we use DBSCAN to group them with the cosine distance,
and retain the group with the highest number as the seeds of RT.












