\section{Methodology overview}

The flow of our methodology is presented in Figure 1.
We take aerial images of the railway area as input,
for which SfM and point clouds are used in advanced with existing software.
We first extract the image line and convert it to a space line with the locally optimal plane of the point cloud.
Then,
we cluster the single 3D line to RT candidates with the frame work derived from DBSCAN,  
during which the texture information of multiple images extracted from ResNet is used as one of the inlier distance.
Having obtained the RT cluster, 
we then trace and reconstruct the vector-based RT in the Kalman framwork,
which fully exploits the RT structure and the multi-view geometries to resolve the uncertainty caused by initial image line segment extraction and the point cloud error.
The railway-track pair is the start seed of our Kalman method.
We first convert image lines to 3D lines with the local optimal plane of the point cloud.
Then,
we cluster the single 3D line to RT pairs with DBSCAN frame work,  
during which the deep feature of multiple images is used as the inlier distance.





\section{Railway track with Kalman filter}

The state to be estimated is in our work is the two points and directions on the railway pair:
\begin{equation}
\mathbf{x} = \begin{bmatrix}
    \mathbf p_1,\mathbf d_1,\mathbf p_2,\mathbf d_2 
\end{bmatrix}^ \top,
\end{equation}
where $\mathbf p_i=\left(x_i, y_i, z_i\right)$ denotes the position 
and $\mathbf d_i=\left(dx_i, dy_i, dz_i\right)$ is the normalized vector represents the direction.
Then,
the linear stochastic difference equation govern the state transition is
\begin{equation}
\mathbf x_{k+1} = 
    \mathrm A \mathbf x_{k} + \mathbf w_k,
    \label{eq_statetransition}
\end{equation}
where $\mathrm A \in R ^ {12 \times 12 }$ is the transition matrix
\begin{equation}
\mathrm A=diag \left(\left\{\mathrm T\right\}_{i=1}^2\right),\quad
\mathrm T=
\left[
\begin{smallmatrix}
\mathbf I_{3\times3}  &  t \cdot \mathbf I_{3\times3} \\
\mathbf 0_{3\times3}  &  \mathbf I_{3\times3}
\end{smallmatrix}
\right]
\end{equation}
and $p \left(\mathbf w_k \right) \sim N(0, Q)$.

we utilize the Kalman Filter to optimize the three-dimensional coordinates and directions of two points. The state vector is defined to encapsulate the positions and directions of both points, represented as a $12$-dimensional vector:
\begin{equation}
\mathbf{x} = \begin{bmatrix}
    \mathbf p_1,\mathbf d_1,\mathbf p_2,\mathbf d_2 
\end{bmatrix}^T
\end{equation}
where $\mathbf p_i=\left(x_i, y_i, z_i\right)$ denotes the position 
and $\mathbf d_i=\left(dx_i, dy_i, dz_i\right)$ represents the direction.
The state transition model assumes that at each time step $t$, each point moves in its respective direction by a fixed distance $t$, while maintaining a constant direction. The state transition matrix $\mathbf{F}$ is constructed as a block diagonal matrix comprising two identical $6 \times 6$ submatrices $\mathbf{F}_p$:
\begin{equation}
\mathbf{F}_p = \begin{bmatrix}
\mathbf{I} & t \cdot \mathbf{I} \\
\mathbf{0} & \mathbf{I} \\
\end{bmatrix}, \quad
\mathbf{F} = \begin{bmatrix}
\mathbf{F}_p & \mathbf{0} \\
\mathbf{0} & \mathbf{F}_p \\
\end{bmatrix}
\end{equation}
where $\mathbf{I}_3$ is the $3 \times 3$ identity matrix and $\mathbf{0}_3$ is the $3 \times 3$ zero matrix. The process noise covariance matrix $\mathbf{Q}$ accounts for uncertainties in position and direction and is similarly structured:
\begin{equation}
\mathbf{Q}_p = \text{diag}(q_p, q_p, q_p, q_d, q_d, q_d), \quad \mathbf{Q} = \text{blkdiag}(\mathbf{Q}_p, \mathbf{Q}_p)
\end{equation}
Here, $q_p$ and $q_d$ represent the process noise variances for the position and direction components, respectively.
The observation model integrates both actual measurements of the points' positions and directions and the imposed constraints. The observation matrix $\mathbf{H}$ is augmented to include these constraints:
\begin{equation}
\mathbf{H} = \begin{bmatrix}
\mathbf{I}_{12} \\
\mathbf{H}_c \\
\mathbf{H}_{dr}
\end{bmatrix}
\end{equation}
where $\mathbf{I}_{12}$ is the $12 \times 12$ identity matrix corresponding to the direct measurements of the state vector. The constraint matrices are defined as:
\begin{equation}
\mathbf{H}_c = \begin{bmatrix}
\mathbf{0}_{3 \times 3} & \mathbf{I}_3 & \mathbf{0}_{3 \times 3} & -\mathbf{I}_3
\end{bmatrix}, \quad
\mathbf{H}_{dr} = \begin{bmatrix}
\mathbf{I}_3 & \mathbf{0}_{3 \times 9} & -\mathbf{I}_3
\end{bmatrix}
\end{equation}
The matrix $\mathbf{H}_c$ enforces direction consistency by computing the difference between the directions of the two points:
\begin{equation}
\mathbf{H}_c \mathbf{x} = 
\mathbf d_1 - \mathbf d_2
\end{equation}
Similarly, $\mathbf{H}_{dr}$ imposes relative distance consistency by calculating the relative positions:
\begin{equation}
\mathbf{H}_{dr} \mathbf{x} = 
\mathbf p_1 - \mathbf p_2
\end{equation}

The observation noise covariance matrix $\mathbf{R}$ incorporates both the measurement noise and the noise associated with the constraints:
\begin{equation}
\mathbf{R} = \text{blkdiag}(\mathbf{R}_1, \mathbf{R}_2, \mathbf{R}_c, \mathbf{R}_{dr})
\end{equation}
where $\mathbf{R}_1$ and $\mathbf{R}_2$ correspond to the measurement noise of the first and second points, respectively:
\begin{equation}
\mathbf{R}_1 = \text{diag}(r_p, r_p, r_p, r_d, r_d, r_d), \quad
\mathbf{R}_2 = \text{diag}(r_p, r_p, r_p, r_d, r_d, r_d)
\end{equation}
$\mathbf{R}_c$ and $\mathbf{R}_{dr}$ represent the noise associated with the direction consistency and relative distance constraints:
\begin{equation}
\mathbf{R}_c = \sigma_c^2 \cdot \mathbf{I}_3, \quad
\mathbf{R}_{dr} = \sigma_r^2 \cdot \mathbf{I}_3
\end{equation}
Here, $\sigma_c$ and $\sigma_r$ are the standard deviations controlling the strictness of the direction consistency and relative distance constraints, respectively.

The Kalman Filter operates through iterative prediction and update steps. In the prediction step, the state vector and covariance matrix are projected forward using the state transition model:
\begin{equation}
\mathbf{x}_{k+1|k} = \mathbf{F} \mathbf{x}_k
\end{equation}
\begin{equation}
\mathbf{P}_{k+1|k} = \mathbf{F} \mathbf{P}_k \mathbf{F}^T + \mathbf{Q}
\end{equation}
In the update step, both the actual measurements and the constraints are incorporated. The combined observation vector $\mathbf{z}$ includes the actual measurements and the desired constraint outcomes (typically zero, indicating no difference for constraints):
\begin{equation}
\mathbf{z} = \begin{bmatrix}
\mathbf{z}_{\text{actual}},
\mathbf{0}_{1 \times 6}
\end{bmatrix}^\top
\end{equation}
The observation residual $\mathbf{y}$ is computed as:
\begin{equation}
\mathbf{y} = \mathbf{z} - \mathbf{H} \mathbf{x}_{k+1|k}
\end{equation}
The residual covariance $\mathbf{S}$ and the Kalman Gain $\mathbf{K}$ are then determined:
\begin{equation}
\mathbf{S} = \mathbf{H} \mathbf{P}_{k+1|k} \mathbf{H}^T + \mathbf{R}
\end{equation}
\begin{equation}
\mathbf{K} = \mathbf{P}_{k+1|k} \mathbf{H}^T \mathbf{S}^{-1}
\end{equation}
Finally, the state vector and covariance matrix are updated:
\begin{equation}
\mathbf{x}_{k+1} = \mathbf{x}_{k+1|k} + \mathbf{K} \mathbf{y}
\end{equation}
\begin{equation}
\mathbf{P}_{k+1} = (\mathbf{I}_{12} - \mathbf{K} \mathbf{H}) \mathbf{P}_{k+1|k}
\end{equation}

Through this iterative process, the Kalman Filter effectively fuses actual measurements with the imposed constraints, refining the estimates of the two points' positions and directions. The direction consistency constraint ensures that the directional vectors of the two points remain aligned, while the relative distance constraint maintains a stable spatial relationship between them. Proper tuning of the noise covariance matrices $\mathbf{Q}$ and $\mathbf{R}$ is essential to balance the influence of the process dynamics and the strength of the constraints on the state estimation.

\section{Accurate railway line reconstruction}

\section{The seed generation for railway track}
We construct the rough 3D line based on the dense point cloud.
Given the end point $\mathbf p$ of a 2D line segment,
we randomly sample three space points around $\mathbf p$ to construct the plane $\pi$,
and we cast a ray $\mathbf r$ passing through $\mathbf p$ from the camera center.
Then,
the 3D point candidate $\mathrm P \in R ^ {3\times1}$ for $\mathbf p$ can be obtained by $\mathbf r$-to-$\pi$ intersection,
and the candidate 3D line $\mathrm L$ can be represented by the two 3D point:
\begin{equation}
    L =\left\{\textit{inter} \left(\pi,\mathbf r_1\right),\textit{inter} \left(\pi,\mathbf r_2\right)  \right\},
\end{equation}
where $\mathbf r_1$ and $\mathbf r_2$ are the rays of the two endpoints,
and \textit{inter} calculates the ray-to-plane intersection.
After random sampling of $n$ times,
we obtain a set of candidate 3D lines $\left\{ L\right\}_{i=1}^n$ and use the LMEDS algorithm,
which does not require an inlier threshold, to confirm the best 3D line for a 2D line:
\begin{equation}
    L^* = \arg\min_{L_i} \text{median} \left\{ d_{i1}, d_{i2}, \dots, d_{in}\right\} ,
\end{equation}
where $d_{ij}$ is the distance between $L_i$ and $L_j$.  

We group two 3D lines as a RT pair based on their angle $\theta_{i,j}$,
overlap $o_{i,j}$,
and projection distance $d_{i,j}$:
\begin{equation}
   \left\{ RT= \left(L_i, L_j\right) \mid \theta_{i,j} < t_\theta, o_{i,j} > t_o, d_{i,j} \in I  \right\},
    \label{eq_geometrycons}
\end{equation}
$\theta_{i,j}$ and $o_{i,j}$are easy to choose,
e.g.,
$5^\circ$ and 60\%,
because the RT pair is parallel and highly overlapped;
while the interval $I$ needs the rough width $\omega$ between the two RT,
which can be acquired from construction standards or point clouds.
We recommend setting $I=\left[2/3\omega,4/3\omega\right]$ that uses one-third of $\omega$ as the margin of error.
Because a 3D line may satisfy \cref{eq_geometrycons} with many others,
the greedy algorithm is used to assign the candidate pair,
which uses the sum of the overlap rate as the maximum score.

We sort the RT based on their scores of the geometry alignment and select the top 10\% RT and use contextual information to further validate the RT pair.
In detail,
if the RT's central line is within $1^\circ$ and $t$ projection distance with another RT,
its score is increased by $\mathcal{N}\left(\mu, \left(t/3\right)^2\right)$.
we use the global average pooling layer in ResNet50 to describe the feature of the RT pair.
Because it has been trained on massive amounts of data and can capture texture information for classification in the absence of labels.
Also, 
we re-transform the image blocks to reduce the ambiguity caused by scale and rotation.
After extraction of RT features, 
we use DBSCAN to group them with the cosine distance,
and retain the group with the highest number as the seeds of RT.












