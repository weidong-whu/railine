\section{Methodology}

The flow of our methodology is presented in Figure 1.
We take aerial images of the railway area as input,
for which SfM and point clouds are used in advanced with existing software.
We first extract the image line and convert it to a space line with the locally optimal plane of the point cloud.
Then,
we cluster the single 3D line to RT candidates with the frame work derived from DBSCAN,  
during which the texture information of multiple images extracted from ResNet is used as one of the inlier distance.
Having obtained the RT cluster, 
we then trace and reconstruct the vector-based RT in the Kalman framwork,
which fully exploits the RT structure and the multi-view geometries to resolve the uncertainty caused by initial image line segment extraction and the point cloud error.
The railway-track pair is the start seed of our Kalman method.
We first convert image lines to 3D lines with the local optimal plane of the point cloud.
Then,
we cluster the single 3D line to RT pairs with DBSCAN frame work,  
during which the deep feature of multiple images is used as the inlier distance.





\subsection{Railway track with Kalman filter}
For a point $\mathbf p=\left(x,y,z\right)$ on the \textit{RL}, 
we can calculate its normalized local direction $\mathbf d=\left(dx,dy,dz\right)$,
and we use  two points and directions to represent the state of the local \textit{RLP}.
Denote the two points as $\mathbf p_1$ and $\mathbf p_2$,  
and denote the directions of the two points as $\mathbf d_1$ and $\mathbf d_2$.
Obviously,
the \textit{RLP} has fixed geometry patterns
we introduce two geometry constraints for them in the filter process:
(1) $\mathbf d_1$ and $\mathbf d_2$ should be as close as possible;
and (2) the change in distance between $\mathbf p_1$ and $\mathbf p_2$ is as small as possible during the filter process.
Then,
the state to be estimated in Kalman filter is
\begin{equation}
\mathbf{x_k} = \begin{bmatrix}
    \mathbf p_{k,1} & \mathbf d_{k,1} & \mathbf p_{k,2} & \mathbf d_{k,2}  & \mathbf p_{k,1}-\mathbf p_{k,2} & \mathbf d_{k,1}-\mathbf d_{k,2}
\end{bmatrix}^ \top \in R^{18}.
\end{equation}
In the following contents,
we use the superscript $pre$ like $\mathbf{x}^{pre}$ or $\mathbf{p}_1^{pre}$  to denote the prediction variable
and use superscript $obs$ like $\mathbf{x}^{obs}$ or $\mathbf{p}_1^{obs}$  to show the observation variable.
We use a scalar $t$ to control the prediction during the transition along the \textit{RL}:
\begin{equation}
        \mathbf{x}^{pre}_k= 
        \mathrm F \mathbf{x}_{k-1}, \quad  
        \mathrm F=\operatorname{diag}\left(\mathrm I,t \! \cdot \! \mathrm I, \mathrm I, t \! \cdot \! \mathrm I, \mathrm I , \mathrm I\right)
        \label {eq_statetransition}
\end{equation}
where $\mathrm I$ is $3\times3$ identity matrix.
In each transition,
the observation state is acquired as follows:
for $\mathbf{p}_{k,i}^{obs}$ and $\mathbf{d}_{k,i}^{obs}$,
we reconstruct the 3D line with multiple images (\cref*{sec_linereconstruction}),
with which the actual position and direction can be calculated;
$\mathbf p_{k,1}^{obs}-\mathbf p_{k,2}^{obs}$ is set as $\mathbf 0$ to make the direction consistent;
for $\mathbf d_{k,1}^{obs}-\mathbf d_{k,2}^{obs}$,
we want it to be equal during the transition,
thus setting it as the last state directly.
Thus,
the observation state is summarized by
\begin{equation}
    \mathbf{x}^{obs}_k= 
    \begin{bmatrix}
        \mathbf p_{k,1}^{obs} & \mathbf d_{k,1}^{obs} & \mathbf p_{k,2}^{obs} & \mathbf d_{k,2}^{obs}
          &\mathbf p_{k-1,1}-\mathbf p_{k-1,2} & \mathbf 0
    \end{bmatrix}^ \top \in R^{18}.
    \label {eq_observation}
\end{equation}

Thus,
the measurement can be the same as $\mathbf x_k$,
and the general Kalman filter to track the \textit{RPL} is
\begin{equation}
    \mathbf {\hat x}_k =\mathbf {\hat x}_k^{\mbox -}+ \mathrm K\left(\mathbf z_k - \mathbf {\hat x}_k^{\mbox -}\right),\quad
    \mathbf z_k = \mathbf x_k+ \mathbf v_k,
\end{equation}
where $p \left(\mathbf v_k \right) \sim N(0, R)$,
$\mathbf {\hat x}_k^{\mbox -}$ is the prediction with \cref{eq_statetransition},
and $\mathrm K$ is the Kalman gain that iteratively calculated from the estimate error.
Please refer to (ref) for the details of Kalman gain. 

Now

\subsection{Accurate railway line reconstruction}
\label{sec_linereconstruction}

\subsection{The seed generation for railway track}
We construct the rough 3D line based on the dense point cloud.
Given the end point $\mathbf p$ of a 2D line segment,
we randomly sample three space points around $\mathbf p$ to construct the plane $\pi$,
and we cast a ray $\mathbf r$ passing through $\mathbf p$ from the camera center.
Then,
the 3D point candidate $\mathrm P \in R ^ {3\times1}$ for $\mathbf p$ can be obtained by $\mathbf r$-to-$\pi$ intersection,
and the candidate 3D line $\mathrm L$ can be represented by the two 3D point:
\begin{equation}
    L =\left\{\textit{inter} \left(\pi,\mathbf r_1\right),\textit{inter} \left(\pi,\mathbf r_2\right)  \right\},
\end{equation}
where $\mathbf r_1$ and $\mathbf r_2$ are the rays of the two endpoints,
and \textit{inter} calculates the ray-to-plane intersection.
After random sampling of $n$ times,
we obtain a set of candidate 3D lines $\left\{ L\right\}_{i=1}^n$ and use the LMEDS algorithm,
which does not require an inlier threshold, to confirm the best 3D line for a 2D line:
\begin{equation}
    L^* = \arg\min_{L_i} \text{median} \left\{ d_{ij}\right\}_{j=1}^n ,
\end{equation}
where $d_{ij}$ is the projection distance between $L_i$ and $L_j$.  

We group two 3D lines as a RT pair based on their angle $\theta_{i,j}$,
overlap $o_{i,j}$,
and projection distance $d_{i,j}$:
\begin{equation}
   \left\{ RT= \left(L_i, L_j\right) \mid \theta_{i,j} < t_\theta, o_{i,j} > t_o, d_{i,j} \in I  \right\},
    \label{eq_geometrycons}
\end{equation}
$\theta_{i,j}$ and $o_{i,j}$are easy to choose,
e.g.,
$5^\circ$ and 60\%,
because the RT pair is parallel and highly overlapped;
while the interval $I$ needs the rough width $\omega$ between the two RT,
which can be acquired from construction standards or point clouds.
We recommend setting $I=\left[2/3\omega,4/3\omega\right]$ that uses one-third of $\omega$ as the margin of error.
Because a 3D line may satisfy \cref{eq_geometrycons} with many others,
the greedy algorithm is used to assign the candidate pair,
which uses the sum of the overlap rate as the maximum score.

We sort the RT based on their scores of the geometry alignment and select the top 10\% RT and use contextual information to further validate the RT pair.
In detail,
if the RT's central line is within $1^\circ$ and $t$ projection distance with another RT,
its score is increased by $\mathcal{N}\left(\mu, \left(t/3\right)^2\right)$.
we use the global average pooling layer in ResNet50 to describe the feature of the RT pair.
Because it has been trained on massive amounts of data and can capture texture information for classification in the absence of labels.
Also, 
we re-transform the image blocks to reduce the ambiguity caused by scale and rotation.
After extraction of RT features, 
we use DBSCAN to group them with the cosine distance,
and retain the group with the highest number as the seeds of RT.












