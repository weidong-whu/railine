\section{Methodology}

The flow of our methodology is presented in Figure 1.
We take aerial images of the railway area as input,
for which SfM and point clouds are used in advanced with existing software.
We first extract the image line and convert it to a space line with the locally optimal plane of the point cloud.
Then,
we cluster the single 3D line to RT candidates with the frame work derived from DBSCAN,  
during which the texture information of multiple images extracted from ResNet is used as one of the inlier distance.
Having obtained the RT cluster, 
we then trace and reconstruct the vector-based RT in the Kalman framwork,
which fully exploits the RT structure and the multi-view geometries to resolve the uncertainty caused by initial image line segment extraction and the point cloud error.
The railway-track pair is the start seed of our Kalman method.
We first convert image lines to 3D lines with the local optimal plane of the point cloud.
Then,
we cluster the single 3D line to RT pairs with DBSCAN frame work,  
during which the deep feature of multiple images is used as the inlier distance.


\section{The seed of 3D railway-track pairs}
We construct the rough 3D line based on the dense point cloud.
Given the end point $\mathbf p$ of a 2D line segment,
we randomly sample three space points around $\mathbf p$ to construct the plane $\pi$,
and we cast a ray $\mathbf r$ passing through $\mathbf p$ from the camera center.
Then,
the 3D point candidate $\mathrm P \in R ^ {3\times1}$ for $\mathbf p$ can be obtained by $\mathbf r$-to-$\pi$ intersection,
and the candidate 3D line $\mathrm L$ can be represented by the two 3D point:
\begin{equation}
    L =\left\{\textit{inter} \left(\pi,\mathbf r_1\right),\textit{inter} \left(\pi,\mathbf r_2\right)  \right\},
\end{equation}
where $\mathbf r_1$ and $\mathbf r_2$ are the rays of the two endpoints,
and \textit{inter} calculates the ray-to-plane intersection.
After random sampling of $n$ times,
we obtain a set of candidate 3D lines $\left\{ L\right\}_{i=1}^n$ and use the LMEDS algorithm,
which does not require an inlier threshold, to confirm the best 3D line for a 2D line:
\begin{equation}
    L^* = \arg\min_{L_i} \text{median} \left\{ d_{i1}, d_{i2}, \dots, d_{in}\right\} ,
\end{equation}
where $d_{ij}$ is the distance between $L_i$ and $L_j$.  

We group two 3D lines as a RT pair based on their angle $\theta_{i,j}$,
overlap $o_{i,j}$,
and projection distance $d_{i,j}$:
\begin{equation}
   \left\{ RT= \left(L_i, L_j\right) \mid \theta_{i,j} < t_\theta, o_{i,j} > t_o, d_{i,j} \in I  \right\},
    \label{eq_geometrycons}
\end{equation}
$\theta_{i,j}$ and $o_{i,j}$are easy to choose,
e.g.,
$5^\circ$ and 60\%,
because the RT pair is parallel and highly overlapped;
while the interval $I$ needs the rough width $\omega$ between the two RT,
which can be acquired from construction standards or point clouds.
We recommend setting $I=\left[2/3\omega,4/3\omega\right]$ that uses one-third of $\omega$ as the margin of error.
Because a 3D line may satisfy \cref{eq_geometrycons} with many others,
the greedy algorithm is used to assign the candidate pair,
which uses the sum of the overlap rate as the maximum score.
Then,
we score the RT based on their geometry alignment with others.

We use contextual information to further validate the RT pair.
Because many publicly available deep networks have been trained on massive amounts of data,
which can capture texture information for classification in the absence of explicit labels,
we directly use the global average pooling layer in ResNet50 to describe the feature of the RT pair.
Also,
we re-transform the image blocks to reduce the ambiguity caused by scale and rotation.
After extraction of features for all image blocks, 
we use the DBSCAN method to group them with the cosine distance,
and we retain the group with the highest number as the seeds of RT.
Since we aim to find the seed point for the Kalman process,
for which accuracy is more important than completeness,
we use a strict distance threshold in DBSCAN to control false positive. 
Finally,
we merge repetitive RT and remove isolated RT based on the projection distance of adjacent RT pairs.
\subsection{Re-triangulation with railway geometries}












